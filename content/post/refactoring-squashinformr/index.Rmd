---
title: "Refactoring squashinformr `r emo::ji('hammer_and_wrench')`"
author: "Hayden MacDonald"
date: "2021-02-10"
output:
  blogdown::html_page:
    toc: false
slug: refactoring-squashinformr
image_preview: ""
tags: 
- R
- code
- best-practices
description: "Using software development best practices to improve R package maintainability."
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(emo)
```


In the early days of the pandemic, I wrote [`squashinformr`](/post/introducing-squashinformr){ target="_blank"}, an R package for web scraping professional squash data. I'm quite proud of the package, as it was my first real effort in creating open source. But when I wrote the initial version, I committed many cardinal programming sins.

At the time, my approach to writing code was very 'script-like'. I kept code for my analyses in single Rmarkdown files that I would run from top to bottom. It's clear looking at old `squashinformr` code that I expected functions to behave the same way. That is, I wrote the functions as if they were individual scripts that had no common behaviour or tasks. In reality, some functions contained identical code except for a few substituted variables. In short, the code was a mess and vulnerable to bugs.

Since then, I've learned software development best practices with the help of a mentor at work. Feeling more confident about my ability to write stable code, I refactored `squashinformr` earlier this year. I'd like to break down examples of where I applied these best practices as if I were speaking to my past self. If you haven't heard of these rules, I recommend you apply some of them in your work. That way, you or someone else does not have to rewrite your code in the future `r emo::ji("smile")`
&nbsp;  

## Beware copy + paste

This is a tip that you might have heard before and, like me, ignored out of convenience. Copying and pasting code is an quick and easy solution in the moment. Unfortunately, it is also a sure way to accrue [technical debt](https://en.wikipedia.org/wiki/Technical_debt){ target="_blank" }. It is an easy way to implement the logic you need, but it comes with a catch: it (at least) doubles the length of your code. I made this mistake when writing `squashinformr` many times over by doing something like this: 

```{r, eval=FALSE}
get_some_data <- function(category = c("mens", "womens", "both")) {

  if (category == "mens") {
  	## [Code to get men's data]
  	## [Data cleaning]
  }

  else if (category == "womens") {
  	## [ Code to get women's data]
  	## [Data cleaning]
  }

  ## [Common data operations]
  return(result)

}
```
&nbsp;  
The consequence of lengthening your code is explained eloquently by [Andrew Tannenbaum](https://books.google.co.uk/books?id=Pd-z64SJRBAC&newbks=0&hl=en&source=newbks_fb&redir_esc=y){ target="_blank" }:

>In addition, a substantial number of the problems caused by buggy software, which occurs because vendors keep adding more and more features to their programs, which inevitably means more code and thus more bugs.

My pseudo-code function above is waiting for a bug to ruin it. The code that retrieved the men's data was nearly identical to the code that retrieved the women's data. If I wanted to introduce a change or a bug stopped the function from working, I would have to rewrite code in up to four separate places to ensure consistent results. It's a similar story when it comes to code commenting. I would have to rewrite the comments in up to four places if they were common between each workflow. This is why it's in our best interest to avoid copying and pasting code. Not only does it make code more vulnerable, but it also creates more work for you in the future.

So what is the alternative strategy to copying and pasting? Writing functions. When you are about to write code that repeats the same logic as other code you've written, it's time to consider whether you should start writing a function. Hadley Wickham wrote a good rule of thumb for this in his [R for Data Science book](https://r4ds.had.co.nz/functions.html){ target="_blank" }:

> You should consider writing a function whenever you've copied and pasted a block of code more than twice (i.e. you now have three copies of the same code).

While refactoring `squashinformr`, I wrote new helper functions that achieved subtasks within the package's main functions. The result looks something like this:

```{r, eval=FALSE}
get_some_data <- function(category = c("mens", "womens", "both")) {

  if (category == "mens") {
    result <- helper_function(category = category)
  }

  else if (category == "womens") {
    result <- helper_function(category = category)
  }

  ## [Common data operations]
  return(result)

}


helper_function <- function(category = c("mens", "womens", "both")) {

  ## [Code to get data, given category]
  ## [Data cleaning]
  return(data)

}
```
&nbsp;  
The code that gets the data is now abstracted away from the main function. The result is succinct code that achieves the desired result without accruing technical debt. 

By avoiding copying and pasting, we can make our code more robust and maintainable for the future.

## Determine requirements by drawing a diagram

It's easy to get inspired about a project idea and want to dive straight in to making it. This happened to me when I wrote `squashinformr`. I was excited by the idea of writing an R package and I had already written code that achieved some of the basic functionality. So I just started writing code and putting hours of time into something I had not thought through. To quote Jurassic Park:

> Yeah, yeah, but your scientists were so preoccupied with whether or not they could that they didn't stop to think if they should.

In other words, I started writing code before determining what the end product should be. I didn't think about how many functions I would be writing or what they should deliver. I didn't consider how those functions could share subtasks so I didn't write helper functions. I ended up wasting a lot of time because of this mistake. To be honest, if I had determined the package's [requirements](https://en.wikipedia.org/wiki/Software_requirements){ target="_blank" } beforehand, I wouldn't have written this blog post.

Instead, I could have achieved a high-level vision of the package by drawing a diagram. Using three `squashinformr` functions as an example, the diagram could look like this:  
&nbsp;  

<img src="/squashinformr-diagram-2.png" alt="Requirements Diagram Example" />

By creating this diagram, I've forced myself to think about how the final product works. I'm forced to think about the package functions as a whole. I have to consider the steps that each function takes towards its desired behaviour. And I also have to think about which functions share logic and which logic is unique to them (e.g. data cleaning). This exercise is informative even if you are the one who came up with the project idea. It helps you determine the scope of the project and leads you toward a refined vision of what you're about to do.

Developments teams will have their own processes for determining requirements, which may be too formal for some personal projects. That's why I recommend this method. You can decide how formal or detailed you want to be so you don't exhaust your inspiration in the planning stage. At the same time, you don't dive in and hope for the best. At the very least, you have an image you can reference to keep your on track with the high-level purpose of your project.

## Continuous testing

One thing I did well in the first version of `squasinformr` was [testing](https://r-pkgs.org/tests.html){ target="_blank" }. I wrote two main types of tests for every function . Equality tests (i.e. "this function with these inputs should return **exactly** this result") and input error tests (e.g. "this function with these inputs should return an error"). All credit to the `testthat` package, which makes it easy for everyone to implement these kinds of tests. The benefit of these tests was that I could run these tests every time I changed something. The results would tell me if a function was behaving as expected or return an error if it wasn't. So all was good while I developed the package but I forgot to consider something important. How was I going to continue to test these functions after I released `squashinformr` to the world?

After releasing a package, you take on responsibility for it. Software packages need maintenance and you are the person people go to if it has issues. So, it's best that you are the first person to know when something is wrong. This is where continuous testing comes in. Writing software tests is great, but it's not enough to run them every once in a while. You need to run tests continuously on an interval that make sense. If your software is niche and not integral to other people's work, you can afford to test less often. If it is integral to other people's work and a lot of people use it, you should be constantly testing.


[Clean up this section and make it a smooth introduction to GitHub Actions for testing]
So how do you actually conduct tests on a regular interval? Additionally, how do you run tests on many operating systems? Thankfully, there is GitHub Actions. If you already host your project on GitHub, the good news is that the R and wider GitHub community have procured thousands of useful tests.

